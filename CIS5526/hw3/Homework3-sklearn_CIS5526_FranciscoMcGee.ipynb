{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3: Classification using sklearn  \n",
    "- Francisco McGee\n",
    "- CIS 5526, FALL 2018\n",
    "- Dr. Slobodan Vucetic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HEADS UP!!!!!\n",
    "- I'm going to do all the processing for adult_data first, and then I'm going to run the adult_data through the sklearn pipeline along with the original datasets, including the iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "\n",
    "import pandas as pd\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions, variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "page_break = \"#\" * 85\n",
    "\n",
    "\n",
    "def get_columns_dict(header):\n",
    "    header_dict = dict()\n",
    "    counter = 1\n",
    "    for item in header:\n",
    "        header_dict[item] = counter\n",
    "        counter += 1\n",
    "    return header_dict\n",
    "\n",
    "def get_column_index(columns, header_dict):\n",
    "    index = []\n",
    "    for column in columns:\n",
    "        index.append(header_dict[column])\n",
    "    \n",
    "    index[:] = [x - 1 for x in index]\n",
    "    return index\n",
    "\n",
    "def get_columns(header_string):\n",
    "    lines = header_string.splitlines()\n",
    "    header = []\n",
    "    for line in lines:\n",
    "        sub_line = line.split(\" \")\n",
    "        for sub in sub_line:\n",
    "            if \":\" in sub:\n",
    "                word = sub.replace(\":\", \"\")\n",
    "                header.append(word)\n",
    "    return header\n",
    "\n",
    "\n",
    "\n",
    "def get_uniques(df, should_encode):\n",
    "    uniques = dict()\n",
    "    \n",
    "    for column in data:\n",
    "        if column in should_encode:\n",
    "            uniques[column] = data[column].unique()\n",
    "    \n",
    "    return uniques\n",
    "\n",
    "\n",
    "def get_one_hot_column(uniques_column):\n",
    "    values = array(uniques_column)                                 # to numpy array\n",
    "    label_encoder = LabelEncoder()                                 # create LabelEncoder\n",
    "    # integer encoding\n",
    "    integer_encoded = label_encoder.fit_transform(values)          # perform integer encoding\n",
    "    # binary encode\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)                             # create one-hot encoder\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)       # reshape\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)           # perform one-hot encoding\n",
    "    return onehot_encoded\n",
    "\n",
    "\n",
    "# input: Pandas dataframe, and a list of columns that need to be one-hot encoded\n",
    "# output: one-hot encoded Pandas dataframe\n",
    "def get_one_hot_df(df, should_encode):\n",
    "    for col in should_encode:    \n",
    "        one_hot = pd.get_dummies(df[col])                  # generate the one-hot version of the column\n",
    "        df = df.drop(col, axis=1)                          # delete the original column\n",
    "        df = pd.concat([df, one_hot], axis=1, sort=False)  # add the one-hot dataframe to the original dataframe\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process adult_data\n",
    "### the next couple blocks of code will munge the adult_data for input to the sklearn ML code\n",
    "(1) get header for adult_data\n",
    "\n",
    "(2) one-hot encode the categorical columns of adult_data in a Pandas dataframe\n",
    "\n",
    "(3) munge the dataframe back into numpy arrays for input into the sklearn ML code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) get header for adult_data\n",
    "- \"column_string\" was copy/pasted from the adult_data description\n",
    "- the following code block parses \"column_string\" to get the columns for the adult_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
      "{'age': 1, 'workclass': 2, 'fnlwgt': 3, 'education': 4, 'education-num': 5, 'marital-status': 6, 'occupation': 7, 'relationship': 8, 'race': 9, 'sex': 10, 'capital-gain': 11, 'capital-loss': 12, 'hours-per-week': 13, 'native-country': 14, 'income': 15}\n",
      "\n",
      "completed get header\n"
     ]
    }
   ],
   "source": [
    "columns_string = '''\n",
    "age: continuous.\n",
    "workclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\n",
    "fnlwgt: continuous.\n",
    "education: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.\n",
    "education-num: continuous.\n",
    "marital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\n",
    "occupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\n",
    "relationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\n",
    "race: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\n",
    "sex: Female, Male.\n",
    "capital-gain: continuous.\n",
    "capital-loss: continuous.\n",
    "hours-per-week: continuous.\n",
    "native-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.\n",
    "'''\n",
    "\n",
    "columns = get_columns(columns_string)\n",
    "columns.append(\"income\")\n",
    "print(columns)\n",
    "columns_dict = get_columns_dict(columns)\n",
    "print(columns_dict)\n",
    "\n",
    "print(\"\\ncompleted get header\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) one-hot encode the categorical columns of adult_data in a Pandas dataframe\n",
    "- import adult_data into a Pandas dataframe\n",
    "- manually identify the categorical columns in \"should_encode\"\n",
    "- manually encode the 'income'\n",
    "- the following code block parses \"column_string\" to get the columns for the adult_data\n",
    "- one-hot encode the necessary columns in the dataframe using \"get_one_hot_df\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed one-hot encoding\n"
     ]
    }
   ],
   "source": [
    "file_name = \"adult.data\"\n",
    "data = pd.read_csv(file_name, names=columns)\n",
    "should_encode = ['race', 'education', 'sex', 'occupation', 'relationship', \n",
    "                 'workclass', 'native-country', 'marital-status']\n",
    "\n",
    "# encode the target column with 0, 1 for classification\n",
    "data['income'] = data['income'].map({' <=50K' : 0, ' >50K' : 1,})\n",
    "data_copy = deepcopy(data)               # keep a deepcopy in case I screw up the original and need it again\n",
    "\n",
    "one_hot_df = get_one_hot_df(data, should_encode) \n",
    "\n",
    "print(\"completed one-hot encoding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) munge the dataframe back into numpy arrays for input into the sklearn ML code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed dataframe munging to lists\n"
     ]
    }
   ],
   "source": [
    "one_hot_df_copy = deepcopy(one_hot_df)\n",
    "one_hot_targets = one_hot_df['income'].tolist()              # this is the y, targets\n",
    "one_hot_df = one_hot_df.drop('income', axis=1)  \n",
    "one_hot_data = one_hot_df.values.tolist()                   # this is the X, training data\n",
    "# convert targets, data to np.array\n",
    "one_hot_targets = np.asarray(one_hot_targets)\n",
    "one_hot_data = np.asarray(one_hot_data)\n",
    "one_hot_dataset = (one_hot_data, one_hot_targets)           # make a tuple of the data, targets\n",
    "\n",
    "print(\"completed dataframe munging to lists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The sklearn stuff starts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### munge the iris datasets a little bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[1.4, 0.2],\n",
      "       [1.4, 0.2],\n",
      "       [1.3, 0.2],\n",
      "       [1.5, 0.2],\n",
      "       [1.4, 0.2],\n",
      "       [1.7, 0.4],\n",
      "       [1.4, 0.3],\n",
      "       [1.5, 0.2],\n",
      "       [1.4, 0.2],\n",
      "       [1.5, 0.1],\n",
      "       [1.5, 0.2],\n",
      "       [1.6, 0.2],\n",
      "       [1.4, 0.1],\n",
      "       [1.1, 0.1],\n",
      "       [1.2, 0.2],\n",
      "       [1.5, 0.4],\n",
      "       [1.3, 0.4],\n",
      "       [1.4, 0.3],\n",
      "       [1.7, 0.3],\n",
      "       [1.5, 0.3],\n",
      "       [1.7, 0.2],\n",
      "       [1.5, 0.4],\n",
      "       [1. , 0.2],\n",
      "       [1.7, 0.5],\n",
      "       [1.9, 0.2],\n",
      "       [1.6, 0.2],\n",
      "       [1.6, 0.4],\n",
      "       [1.5, 0.2],\n",
      "       [1.4, 0.2],\n",
      "       [1.6, 0.2],\n",
      "       [1.6, 0.2],\n",
      "       [1.5, 0.4],\n",
      "       [1.5, 0.1],\n",
      "       [1.4, 0.2],\n",
      "       [1.5, 0.2],\n",
      "       [1.2, 0.2],\n",
      "       [1.3, 0.2],\n",
      "       [1.4, 0.1],\n",
      "       [1.3, 0.2],\n",
      "       [1.5, 0.2],\n",
      "       [1.3, 0.3],\n",
      "       [1.3, 0.3],\n",
      "       [1.3, 0.2],\n",
      "       [1.6, 0.6],\n",
      "       [1.9, 0.4],\n",
      "       [1.4, 0.3],\n",
      "       [1.6, 0.2],\n",
      "       [1.4, 0.2],\n",
      "       [1.5, 0.2],\n",
      "       [1.4, 0.2],\n",
      "       [4.7, 1.4],\n",
      "       [4.5, 1.5],\n",
      "       [4.9, 1.5],\n",
      "       [4. , 1.3],\n",
      "       [4.6, 1.5],\n",
      "       [4.5, 1.3],\n",
      "       [4.7, 1.6],\n",
      "       [3.3, 1. ],\n",
      "       [4.6, 1.3],\n",
      "       [3.9, 1.4],\n",
      "       [3.5, 1. ],\n",
      "       [4.2, 1.5],\n",
      "       [4. , 1. ],\n",
      "       [4.7, 1.4],\n",
      "       [3.6, 1.3],\n",
      "       [4.4, 1.4],\n",
      "       [4.5, 1.5],\n",
      "       [4.1, 1. ],\n",
      "       [4.5, 1.5],\n",
      "       [3.9, 1.1],\n",
      "       [4.8, 1.8],\n",
      "       [4. , 1.3],\n",
      "       [4.9, 1.5],\n",
      "       [4.7, 1.2],\n",
      "       [4.3, 1.3],\n",
      "       [4.4, 1.4],\n",
      "       [4.8, 1.4],\n",
      "       [5. , 1.7],\n",
      "       [4.5, 1.5],\n",
      "       [3.5, 1. ],\n",
      "       [3.8, 1.1],\n",
      "       [3.7, 1. ],\n",
      "       [3.9, 1.2],\n",
      "       [5.1, 1.6],\n",
      "       [4.5, 1.5],\n",
      "       [4.5, 1.6],\n",
      "       [4.7, 1.5],\n",
      "       [4.4, 1.3],\n",
      "       [4.1, 1.3],\n",
      "       [4. , 1.3],\n",
      "       [4.4, 1.2],\n",
      "       [4.6, 1.4],\n",
      "       [4. , 1.2],\n",
      "       [3.3, 1. ],\n",
      "       [4.2, 1.3],\n",
      "       [4.2, 1.2],\n",
      "       [4.2, 1.3],\n",
      "       [4.3, 1.3],\n",
      "       [3. , 1.1],\n",
      "       [4.1, 1.3],\n",
      "       [6. , 2.5],\n",
      "       [5.1, 1.9],\n",
      "       [5.9, 2.1],\n",
      "       [5.6, 1.8],\n",
      "       [5.8, 2.2],\n",
      "       [6.6, 2.1],\n",
      "       [4.5, 1.7],\n",
      "       [6.3, 1.8],\n",
      "       [5.8, 1.8],\n",
      "       [6.1, 2.5],\n",
      "       [5.1, 2. ],\n",
      "       [5.3, 1.9],\n",
      "       [5.5, 2.1],\n",
      "       [5. , 2. ],\n",
      "       [5.1, 2.4],\n",
      "       [5.3, 2.3],\n",
      "       [5.5, 1.8],\n",
      "       [6.7, 2.2],\n",
      "       [6.9, 2.3],\n",
      "       [5. , 1.5],\n",
      "       [5.7, 2.3],\n",
      "       [4.9, 2. ],\n",
      "       [6.7, 2. ],\n",
      "       [4.9, 1.8],\n",
      "       [5.7, 2.1],\n",
      "       [6. , 1.8],\n",
      "       [4.8, 1.8],\n",
      "       [4.9, 1.8],\n",
      "       [5.6, 2.1],\n",
      "       [5.8, 1.6],\n",
      "       [6.1, 1.9],\n",
      "       [6.4, 2. ],\n",
      "       [5.6, 2.2],\n",
      "       [5.1, 1.5],\n",
      "       [5.6, 1.4],\n",
      "       [6.1, 2.3],\n",
      "       [5.6, 2.4],\n",
      "       [5.5, 1.8],\n",
      "       [4.8, 1.8],\n",
      "       [5.4, 2.1],\n",
      "       [5.6, 2.4],\n",
      "       [5.1, 2.3],\n",
      "       [5.1, 1.9],\n",
      "       [5.9, 2.3],\n",
      "       [5.7, 2.5],\n",
      "       [5.2, 2.3],\n",
      "       [5. , 1.9],\n",
      "       [5.2, 2. ],\n",
      "       [5.4, 2.3],\n",
      "       [5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]))\n",
      "completed munging iris dataset\n"
     ]
    }
   ],
   "source": [
    "iris = sklearn.datasets.load_iris()\n",
    "\n",
    "iris_trunc = []\n",
    "\n",
    "for l in iris.data:\n",
    "    iris_trunc.append(l[2:4].tolist())\n",
    "    \n",
    "iris_data = np.asarray(iris_trunc)\n",
    "iris_dataset = (iris_data, iris.target)\n",
    "\n",
    "print(iris_dataset)\n",
    "print(\"completed munging iris dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here is the original code from the assignment, with 2 added datasets:\n",
    "### (1) iris_dataset\n",
    "### (2) adult_dataset\n",
    "## For convenience, I print out which dataset, classifier, and score.\n",
    "* NOTE: visualization has been disabled for the iris and adult datasets because of dimensionality problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code source: Gaël Varoquaux\n",
    "#              Andreas Müller\n",
    "# Modified for documentation by Jaques Grobler\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "h = .02  # step size in the mesh\n",
    "\n",
    "\n",
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\"]\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "#    GaussianProcessClassifier(1.0 * RBF(1.0), warm_start=True),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1),\n",
    "    AdaBoostClassifier()]\n",
    "#    GaussianNB(),\n",
    "#    QuadraticDiscriminantAnalysis()]\n",
    "\n",
    "\n",
    "X, y = make_classification(n_features=2, n_redundant=0, n_informative=2,\n",
    "                           random_state=1, n_clusters_per_class=1)\n",
    "\n",
    "rng = np.random.RandomState(2)\n",
    "X += 2 * rng.uniform(size=X.shape)\n",
    "linearly_separable = (X, y)\n",
    "\n",
    "datasets = [make_moons(noise=0.3, random_state=0),\n",
    "            make_circles(noise=0.2, factor=0.5, random_state=1),\n",
    "            linearly_separable,\n",
    "            iris_dataset,\n",
    "            one_hot_dataset\n",
    "            ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2700x900 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "figure = plt.figure(figsize=(27, 9))\n",
    "i = 1\n",
    "# iterate over datasets\n",
    "datasets = [make_moons(noise=0.3, random_state=0),\n",
    "            make_circles(noise=0.2, factor=0.5, random_state=1),\n",
    "            linearly_separable,\n",
    "            iris_dataset,\n",
    "            one_hot_dataset\n",
    "            ]\n",
    "dataset_counter_dict = {1: \"moons\", 2: \"circles\", 3: \"linearly_separable\", 4: \"iris_dataset\", 5: \"adult_data\"}\n",
    "\n",
    "dataset_counter = 1\n",
    "\n",
    "scores = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####################################################################################\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "6",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [13], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ds_cnt, ds \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(datasets):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(page_break)\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset:\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[43mdataset_counter_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdataset_counter\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(page_break)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# preprocess dataset, split into training and test part\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 6"
     ]
    }
   ],
   "source": [
    "\n",
    "for ds_cnt, ds in enumerate(datasets):\n",
    "    print(page_break)\n",
    "    print(\"dataset:\\t\", dataset_counter_dict[dataset_counter])\n",
    "    print(page_break)\n",
    "    \n",
    "\n",
    "    # preprocess dataset, split into training and test part\n",
    "    X, y = ds\n",
    "    #print(\"X.shape\", X.shape)\n",
    "    \n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(X, y, test_size=.4, random_state=42)\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "\n",
    "    # just plot the dataset first\n",
    "    cm = plt.cm.RdBu\n",
    "    cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "    ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "    if ds_cnt == 0:\n",
    "        ax.set_title(\"Input data\")\n",
    "    # Plot the training points\n",
    "    ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright)\n",
    "    # and testing points\n",
    "    ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, alpha=0.6)\n",
    "    ax.set_xlim(xx.min(), xx.max())\n",
    "    ax.set_ylim(yy.min(), yy.max())\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    i += 1\n",
    "\n",
    "    # iterate over classifiers\n",
    "    dataset_scores = []\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "        #print(page_break)\n",
    "        #print(\"X_train shape:\", X_train.shape)\n",
    "        #print(page_break)\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        score = clf.score(X_test, y_test)\n",
    "        print(\"\\tname:\", name, \"\\t\\t\\tscore:\", score)\n",
    "        dataset_scores.append(score)\n",
    "\n",
    "        # Plot the decision boundary. For that, we will assign a color to each\n",
    "        # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "        #print(page_break)\n",
    "        #print(\"that np.c_...ravel stuff: \", np.c_[xx.ravel(), yy.ravel()].shape)\n",
    "        #print(\"xx.shape:\", xx.shape, len(xx))\n",
    "        #print(\"yy.shape:\", yy.shape, len(yy))\n",
    "        #print(page_break)\n",
    "\n",
    "        try:\n",
    "            if hasattr(clf, \"decision_function\"):\n",
    "                Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "            else:\n",
    "                Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "\n",
    "            # Put the result into a color plot\n",
    "            Z = Z.reshape(xx.shape)\n",
    "            ax.contourf(xx, yy, Z, cmap=cm, alpha=.8)\n",
    "\n",
    "            # Plot also the training points\n",
    "            ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright)\n",
    "            # and testing points\n",
    "            ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright,\n",
    "                       alpha=0.6)\n",
    "\n",
    "            ax.set_xlim(xx.min(), xx.max())\n",
    "            ax.set_ylim(yy.min(), yy.max())\n",
    "            ax.set_xticks(())\n",
    "            ax.set_yticks(())\n",
    "            if ds_cnt == 0:\n",
    "                ax.set_title(name)\n",
    "            ax.text(xx.max() - .3, yy.min() + .3, ('%.2f' % score).lstrip('0'),\n",
    "                    size=15, horizontalalignment='right')\n",
    "            i += 1\n",
    "        except(ValueError):\n",
    "            print(\"dimensions cannot be visualized\")\n",
    "    scores[dataset_counter_dict[dataset_counter]] = dataset_scores\n",
    "    dataset_counter += 1\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(page_break)\n",
    "print(\"\\n completed sklearn ML pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above trained several types of classifiers on 3 synthetic data sets. Among them are kNN and feedforward neural networks. There are also some other algorithms we will introduce during the course. At the moment, you do not have to worry what they are and how they work. \n",
    "\n",
    "**Question 1**. Study the code and try to understand what each line does. In particular, pay attention to how easy it is to train predictors of different types. Run the code. You should be able to see a nice display demonstrating performance of different algorithms on 3 data sets.\n",
    "\n",
    "**Question 2**. Train all the listed classifiers on Iris data (you can load it using *iris = sklearn.datasets.load_iris()*) and test their accuracy. Report and discuss the results\n",
    "\n",
    "**Question 3**. Play with the hyperparameters of each of the algorithms. Try to improve the accuracy on the test data. \n",
    "\n",
    "**Question 4**. Perform the exploratory data analysis of  the Adult Data Set from http://archive.ics.uci.edu/ml/datasets/Adult. Train and estimate accuracy of all of all the classifiers from Question 1. Note that you will have to preprocess your data set before training. Explain all the preprocessing steps you applied and report on the accuracy on test data. Report all EDA and classification results in a 1-page document.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4 Response:\n",
    "### My steps to pre-process the adult_data were:\n",
    "(1) get header for adult_data\n",
    "\n",
    "(2) one-hot encode the categorical columns of adult_data in a Pandas dataframe\n",
    "\n",
    "(3) munge the dataframe back into numpy arrays for input into the sklearn ML code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, compare accuracy scores of the classifiers across the datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>moons</th>\n",
       "      <th>circles</th>\n",
       "      <th>linearly_separable</th>\n",
       "      <th>iris_dataset</th>\n",
       "      <th>adult_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <td>0.975</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.814818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVM</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.850672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RBF SVM</th>\n",
       "      <td>0.975</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.787869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.950</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.851823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.759693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Net</th>\n",
       "      <td>0.900</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.855969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.950</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.862649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   moons  circles  linearly_separable  iris_dataset  \\\n",
       "Nearest Neighbors  0.975    0.925               0.925      0.983333   \n",
       "Linear SVM         0.875    0.400               0.925      0.983333   \n",
       "RBF SVM            0.975    0.875               0.950      0.983333   \n",
       "Decision Tree      0.950    0.775               0.950      0.983333   \n",
       "Random Forest      0.925    0.750               0.950      0.983333   \n",
       "Neural Net         0.900    0.750               0.950      0.983333   \n",
       "AdaBoost           0.925    0.825               0.950      1.000000   \n",
       "\n",
       "                   adult_data  \n",
       "Nearest Neighbors    0.814818  \n",
       "Linear SVM           0.850672  \n",
       "RBF SVM              0.787869  \n",
       "Decision Tree        0.851823  \n",
       "Random Forest        0.759693  \n",
       "Neural Net           0.855969  \n",
       "AdaBoost             0.862649  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_dict = dict()\n",
    "names_counter = 0\n",
    "for name in names:\n",
    "    names_dict[names_counter] = name\n",
    "    names_counter += 1\n",
    "    \n",
    "\n",
    "scores_df = pd.DataFrame.from_dict(scores)\n",
    "scores_df = scores_df.rename(index=names_dict)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>moons</th>\n",
       "      <th>circles</th>\n",
       "      <th>linearly_separable</th>\n",
       "      <th>iris_dataset</th>\n",
       "      <th>adult_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.932143</td>\n",
       "      <td>0.757143</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>0.826213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.037401</td>\n",
       "      <td>0.170608</td>\n",
       "      <td>0.012199</td>\n",
       "      <td>0.006299</td>\n",
       "      <td>0.039775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.759693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.801344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.850672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.962500</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.853896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.862649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          moons   circles  linearly_separable  iris_dataset  adult_data\n",
       "count  7.000000  7.000000            7.000000      7.000000    7.000000\n",
       "mean   0.932143  0.757143            0.942857      0.985714    0.826213\n",
       "std    0.037401  0.170608            0.012199      0.006299    0.039775\n",
       "min    0.875000  0.400000            0.925000      0.983333    0.759693\n",
       "25%    0.912500  0.750000            0.937500      0.983333    0.801344\n",
       "50%    0.925000  0.775000            0.950000      0.983333    0.850672\n",
       "75%    0.962500  0.850000            0.950000      0.983333    0.853896\n",
       "max    0.975000  0.925000            0.950000      1.000000    0.862649"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.924630</td>\n",
       "      <td>0.786801</td>\n",
       "      <td>0.914241</td>\n",
       "      <td>0.907016</td>\n",
       "      <td>0.878605</td>\n",
       "      <td>0.907753</td>\n",
       "      <td>0.899196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.067161</td>\n",
       "      <td>0.217882</td>\n",
       "      <td>0.082544</td>\n",
       "      <td>0.077503</td>\n",
       "      <td>0.103793</td>\n",
       "      <td>0.058374</td>\n",
       "      <td>0.053040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.814818</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.787869</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.759693</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.850672</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.851747</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.855432</td>\n",
       "      <td>0.862649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.925000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Nearest Neighbors  Linear SVM   RBF SVM  Decision Tree  Random Forest  \\\n",
       "count           5.000000    5.000000  5.000000       5.000000       5.000000   \n",
       "mean            0.924630    0.786801  0.914241       0.907016       0.878605   \n",
       "std             0.067161    0.217882  0.082544       0.077503       0.103793   \n",
       "min             0.814818    0.400000  0.787869       0.800000       0.759693   \n",
       "25%             0.925000    0.850672  0.875000       0.851747       0.775000   \n",
       "50%             0.925000    0.875000  0.950000       0.950000       0.925000   \n",
       "75%             0.975000    0.883333  0.975000       0.950000       0.950000   \n",
       "max             0.983333    0.925000  0.983333       0.983333       0.983333   \n",
       "\n",
       "       Neural Net  AdaBoost  \n",
       "count    5.000000  5.000000  \n",
       "mean     0.907753  0.899196  \n",
       "std      0.058374  0.053040  \n",
       "min      0.850000  0.825000  \n",
       "25%      0.855432  0.862649  \n",
       "50%      0.900000  0.925000  \n",
       "75%      0.950000  0.933333  \n",
       "max      0.983333  0.950000  "
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transposed = scores_df.transpose()\n",
    "transposed.describe()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
